# ðŸ”¥ 3ï¸âƒ£ Distributed Deduplicated Notification Sender

---

## ðŸ§¾ Problem Statement

You are building a distributed notification system.

Events arrive as:

```
(userId, notificationType, timestamp)
```

### Requirement

For each `(userId, notificationType)`:

* Send **at most one notification per hour**
* System runs across **multiple servers**
* Notifications may be retried
* Servers may crash
* Must avoid duplicate sends globally

---

## ðŸŽ¯ Core Goal

Guarantee:

> A user receives at most 1 notification per type per hour â€” even in distributed environment.

---

# ðŸ§  Step 1: Clarify Important Questions

In interview you ask:

1. Is one-hour window sliding or fixed?
   â†’ Assume sliding window.
2. Can slight delay happen?
3. Are we allowed external store?
4. Is it okay if notification fails after marking as sent?
5. Do we need exactly-once delivery or at-most-once?

Assume:

* At-most-once per hour required
* Best effort delivery

---

# ðŸ§  Step 2: Why This Is Different from Problem #2

Problem #2:

* Dedup forever (or TTL-based)
* Based on messageId

This problem:

* Dedup per composite key `(userId, notificationType)`
* With **time window (1 hour)**
* Continuous system

So this is:

> Distributed sliding-window rate limiting per key.

---

# ðŸ§  Step 3: Naive Approach (Wrong)

Each server keeps:

```
Map<(userId, type), lastSentTime>
```

Problem:

* Servers donâ€™t share state
* Duplicate notifications sent across nodes

Rejected.

---

# ðŸ§  Step 4: Correct Direction â€” Distributed TTL Store

We use external store like:

* Redis
* DynamoDB
* Strongly consistent KV store

Key design:

```
Key: userId:notificationType
Value: lastSentTimestamp
TTL: 1 hour
```

---

# ðŸ§  Step 5: Atomic Operation

We need atomic:

```
SET key value NX EX 3600
```

Meaning:

* Set only if not exists
* Expire automatically after 1 hour

If:

* Success â†’ send notification
* Fail â†’ skip

This gives exactly what we want.

---

# ðŸ§  Why This Works

When first notification comes:

```
Key does not exist â†’ SET succeeds â†’ send
```

Within 1 hour:

```
Key exists â†’ SET fails â†’ skip
```

After 1 hour:

```
Key auto expires â†’ next send allowed
```

Beautiful.

---

# ðŸ§  Step 6: Crash Handling

What if:

1. Server successfully sets key
2. Crashes before sending notification

Then user gets nothing for that hour.

Is that acceptable?

Depends on requirement.

If strict guarantee of delivery required:
We need two-phase logic.

---

# ðŸ§  Step 7: Stronger Version (Safer Design)

Instead of sending immediately after SET:

Use state machine:

```
Key: userId:type
Value:
   status: SENDING | SENT
   updatedAt
```

Flow:

1. Atomic insert SENDING
2. Send notification
3. Mark as SENT

If crash before SENT:

* Retry mechanism checks SENDING older than threshold
* Reattempt

But this increases complexity.

---

# ðŸ§  Step 8: Consistent Hashing Optimization

To reduce coordination overhead:

Partition users by hash:

```
hash(userId) % N
```

Each partition handled by specific server.

Now:

* All notifications for same user land on same node
* Dedup can be local

Still need distributed store for crash recovery though.

---

# ðŸ§  Step 9: High Throughput Concerns

If millions of users:

Memory size in Redis:

At peak:

```
ActiveUsers Ã— notificationTypes
```

But TTL auto-cleanup keeps memory bounded.

---

# ðŸ§  Step 10: Java Pseudocode

```java
public boolean shouldSend(String userId, String type, long timestamp) {

    String key = userId + ":" + type;

    boolean inserted = redis.setIfAbsent(key, timestamp, 3600);

    if (inserted) {
        sendNotification(userId, type);
        return true;
    }

    return false;
}
```

---

# ðŸ§  Step 11: Edge Cases

1. Clock skew between servers
2. Redis failure
3. Network partition
4. TTL precision (seconds-level ok?)
5. Retry storms

---

# ðŸ§  Step 12: What Google Is Testing

* Composite-key dedup
* Distributed rate limiting
* TTL-based expiration
* Atomic conditional writes
* Crash consistency reasoning
* Scaling strategy
* Partitioning

---

# ðŸ§  Riyaz-Level Interview Framing

You should say:

> "We model per-user-per-type suppression using an atomic SETNX with TTL in a strongly consistent KV store. This ensures at-most-once delivery per hour globally. For higher reliability, we extend this to a SENDINGâ†’SENT state machine to handle crash recovery."

That sounds senior.

---
